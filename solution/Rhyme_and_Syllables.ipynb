{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "import json\n",
    "from HMM import unsupervised_HMM\n",
    "from HMM_helper import (\n",
    "    text_to_wordcloud,\n",
    "    states_to_wordclouds,\n",
    "    parse_observations,\n",
    "    sample_sentence,\n",
    "    visualize_sparsities,\n",
    "    animate_emission, \n",
    ")\n",
    "import re\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions (Cleanup Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_sonnet_shakespeare(text): \n",
    "    \"\"\"\n",
    "    Split Shakespeare text by sonnet. \n",
    "    \"\"\"\n",
    "    return shakespeare_text.split(\"\\n\\n\\n\")\n",
    "\n",
    "def clean_shakespeare(text): \n",
    "    sonnets = split_by_sonnet_shakespeare(text)\n",
    "    all_lines = []\n",
    "    for i in range(0, len(sonnets)): \n",
    "        lines = sonnets[i].split(\"\\n\")\n",
    "        for j in range(1, len(lines)):\n",
    "            all_lines.append(lines[j])\n",
    "    return '\\n'.join(all_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function (Build Syllables Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_syllables_dict(syllables): \n",
    "    \"\"\"\n",
    "    Build a syllables dictionary. \n",
    "    \"\"\"\n",
    "    lines = [line.split() for line in syllables.split('\\n') if line.split()]\n",
    "    syllables_dict = dict()\n",
    "    for line in lines: \n",
    "        word = line[0]\n",
    "        if len(line) > 2: \n",
    "            # Ignore end-of-line syllable count. \n",
    "            # Keep the larger syllable count if there are multiple possibilities.\n",
    "            if \"E\" in line[1]: \n",
    "                syllables_dict[word] = int(line[2])\n",
    "            elif \"E\" in line[2]: \n",
    "                syllables_dict[word] = int(line[1])\n",
    "            else: \n",
    "                syllables_dict[word] = int(line[2])\n",
    "        else: \n",
    "            syllables_dict[word] = int(line[1])\n",
    "    return syllables_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function (Build Rhyme Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rhyme_pairs_shakespeare(sonnets): \n",
    "    \"\"\"\n",
    "    Build a dictionary of rhyme pairs and their frequency of \n",
    "    occurrence in Shakespeare's sonnets. \n",
    "    \"\"\"\n",
    "    rhyme_pairs = dict()\n",
    "    \n",
    "    for i in range(0, len(sonnets)): \n",
    "        sonnet_num = i + 1\n",
    "        # Excluce Sonnet 99, Sonnet 126, and Sonnet 145. \n",
    "        # Sonnet 99 has 15 lines, Sonnet 126 has 12 lines.\n",
    "        # All other sonnets follow the same rhyme scheme.\n",
    "        if sonnet_num == 99 or sonnet_num == 126: \n",
    "            \n",
    "            # Sonnet 99 has 15 lines of rhyme scheme ababa cdcd efef gg. \n",
    "            # We will throw out the rhyme triple a. \n",
    "            if sonnet_num == 99: \n",
    "                lines = sonnets[i].split(\"\\n\")\n",
    "                end_words = [' ']\n",
    "                \n",
    "                for j in range(1, 16): \n",
    "                    words = lines[j].split(' ')\n",
    "                    last_word = words[-1].strip()\n",
    "                    last_word = re.sub(r'[^\\w\\-\\']', '', last_word).lower()\n",
    "                    end_words.append(last_word)\n",
    "                \n",
    "                # Create pairs of rhyming words. \n",
    "                rhyme1 = (end_words[2], end_words[4])\n",
    "                rhyme2 = (end_words[6], end_words[8])\n",
    "                rhyme3 = (end_words[7], end_words[9])\n",
    "                rhyme4 = (end_words[10], end_words[12])\n",
    "                rhyme5 = (end_words[11], end_words[13])\n",
    "                rhyme6 = (end_words[14], end_words[15])\n",
    "                \n",
    "                rhymes = [rhyme1, rhyme2, rhyme3, rhyme4, rhyme5, rhyme6]\n",
    "                \n",
    "                # Add rhyming pairs to dictionary and keep in track of their \n",
    "                # frequency of occurrence. \n",
    "                for pair in rhymes: \n",
    "                    if pair in rhyme_pairs: \n",
    "                        rhyme_pairs[pair] += 1\n",
    "                    else: \n",
    "                        rhyme_pairs[pair] = 1\n",
    "            \n",
    "            # Sonnet 126 has 12 lines of rhyme scheme aa bb cc dd ee ff. \n",
    "            if sonnet_num == 126: \n",
    "                lines = sonnets[i].split(\"\\n\")\n",
    "                end_words = [' ']\n",
    "                for j in range(1, 13): \n",
    "                    words = lines[j].split(' ')\n",
    "                    last_word = words[-1].strip()\n",
    "                    last_word = re.sub(r'[^\\w\\-\\']', '', last_word).lower()\n",
    "                    end_words.append(last_word)\n",
    "                # Create pairs of rhyming words. \n",
    "                rhyme1 = (end_words[1], end_words[2])\n",
    "                rhyme2 = (end_words[3], end_words[4])\n",
    "                rhyme3 = (end_words[5], end_words[6])\n",
    "                rhyme4 = (end_words[7], end_words[8])\n",
    "                rhyme5 = (end_words[9], end_words[10])\n",
    "                rhyme6 = (end_words[11], end_words[12])\n",
    "                \n",
    "                rhymes = [rhyme1, rhyme2, rhyme3, rhyme4, rhyme5, rhyme6]\n",
    "                \n",
    "                # Add rhyming pairs to dictionary and keep in track of their \n",
    "                # frequency of occurrence. \n",
    "                for pair in rhymes: \n",
    "                    if pair in rhyme_pairs: \n",
    "                        rhyme_pairs[pair] += 1\n",
    "                    else: \n",
    "                        rhyme_pairs[pair] = 1\n",
    "                    \n",
    "        else: \n",
    "            # Append the last word of each line (remove punctuation)\n",
    "            lines = sonnets[i].split(\"\\n\")\n",
    "            end_words = [' ']\n",
    "            for j in range(1, 15): \n",
    "                words = lines[j].split(' ')\n",
    "                last_word = words[-1].strip()\n",
    "                last_word = re.sub(r'[^\\w\\-\\']', '', last_word).lower()\n",
    "                end_words.append(last_word)\n",
    "            \n",
    "            # Create pairs of rhyming words. Shakespeare's sonnets has the \n",
    "            # following rhyming structure per line: abab, cdcd, efef, gg. \n",
    "            rhyme1 = (end_words[1], end_words[3])\n",
    "            rhyme2 = (end_words[2], end_words[4])\n",
    "            rhyme3 = (end_words[5], end_words[7])\n",
    "            rhyme4 = (end_words[6], end_words[8])\n",
    "            rhyme5 = (end_words[9], end_words[11])\n",
    "            rhyme6 = (end_words[10], end_words[12])\n",
    "            rhyme7 = (end_words[13], end_words[14])\n",
    "            \n",
    "            rhymes = [rhyme1, rhyme2, rhyme3, rhyme4, rhyme5, rhyme6, rhyme7]\n",
    "            \n",
    "            # Add rhyming pairs to dictionary and keep in track of their \n",
    "            # frequency of occurrence. \n",
    "            for pair in rhymes: \n",
    "                if pair in rhyme_pairs: \n",
    "                    rhyme_pairs[pair] += 1\n",
    "                else: \n",
    "                    rhyme_pairs[pair] = 1\n",
    "                    \n",
    "    return rhyme_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions (Generate Emissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_emission1(self, M, seed):\n",
    "        '''\n",
    "        Generates an emission of length M, assuming that the starting state\n",
    "        is chosen uniformly at random. \n",
    "\n",
    "        Arguments:\n",
    "            M:          Length of the emission to generate.\n",
    "\n",
    "        Returns:\n",
    "            emission:   The randomly generated emission as a list.\n",
    "\n",
    "            states:     The randomly generated states as a list.\n",
    "        '''\n",
    "        \n",
    "        #O: The (i, j)^th element is the probability of\n",
    "        # emitting observation j given state i.\n",
    "        O = np.array(self.O)\n",
    "        emission = []\n",
    "        emission.append(seed)\n",
    "       \n",
    "        # generate first state given this emission \n",
    "        col_states = O[:, seed]\n",
    "       \n",
    "        # Choose the state having the highest probability of generating\n",
    "        # this emission. \n",
    "        \n",
    "        state = np.argmax(col_states)       \n",
    "        states = []\n",
    "        for t in range(M-1):\n",
    "            # Append state.\n",
    "            states.append(state)\n",
    "\n",
    "            # Sample next observation.\n",
    "            rand_var = random.uniform(0, 1)\n",
    "            next_obs = 0\n",
    "\n",
    "            while rand_var > 0:\n",
    "                rand_var -= self.O[state][next_obs]\n",
    "                next_obs += 1\n",
    "\n",
    "            next_obs -= 1\n",
    "            emission.insert(0, next_obs)\n",
    "\n",
    "            # Sample next state.\n",
    "            rand_var = random.uniform(0, 1)\n",
    "            next_state = 0\n",
    "\n",
    "            while rand_var > 0:\n",
    "                rand_var -= self.A[state][next_state]\n",
    "                next_state += 1\n",
    "\n",
    "            next_state -= 1\n",
    "            state = next_state\n",
    "\n",
    "        return emission, states\n",
    "    \n",
    "def obs_map_reverser1(obs_map):\n",
    "    obs_map_r = {}\n",
    "\n",
    "    for key in obs_map:\n",
    "        obs_map_r[obs_map[key]] = key\n",
    "\n",
    "    return obs_map_r\n",
    "\n",
    "def parse_observations_reverse(text):\n",
    "    # Convert text to dataset.\n",
    "    lines = [line.split() for line in text.split('\\n') if line.split()]\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    for line in reversed(lines):\n",
    "        obs_elem = []\n",
    "        \n",
    "        for word in reversed(line):\n",
    "            word = re.sub(r'[^\\w\\-\\']', '', word).lower() \n",
    "            #word = re.sub(r'[^\\w]', '', word).lower()\n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "            \n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "        \n",
    "        # Add the encoded sequence.\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sentence1(hmm, obs_map, seed, n_syllables=10):\n",
    "    \"\"\"\n",
    "    Generate a sentence with the given number of syllables and seed word.  \n",
    "    \"\"\"\n",
    "    # Get reverse map.\n",
    "    seed_idx = obs_map[seed]\n",
    "    obs_map_r = obs_map_reverser1(obs_map)\n",
    "    sentence = []\n",
    "    \n",
    "    # Keep generating until we are able to obtain a line \n",
    "    # that can be truncated to exactly n_syllables number of \n",
    "    # syllables.    \n",
    "    while True: \n",
    "        count = 0\n",
    "        sentence = []\n",
    "        emission, states = generate_emission1(hmm, 10, seed_idx)\n",
    "        emission = emission[::-1]\n",
    "        for i in emission: \n",
    "            word = obs_map_r[i]\n",
    "            syllables_count = syllables_dict[word]\n",
    "            count += syllables_count\n",
    "            sentence.append(word)\n",
    "            if count >= n_syllables: \n",
    "                break\n",
    "        if count == n_syllables: \n",
    "            break        \n",
    "\n",
    "    return ' '.join(sentence[::-1]).capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_shakespeare_sonnet(hmm, obs_map, rhyme_pairs): \n",
    "    \"\"\"\n",
    "    Generate a poem following the rhyme scheme of a typical Shakespeare\n",
    "    Sonnet (abab cdcd efef gg)\n",
    "    \"\"\"\n",
    "    poem = ''\n",
    "    (a1, a2) = rhyme_pairs[0]\n",
    "    (b1, b2) = rhyme_pairs[1]\n",
    "    (c1, c2) = rhyme_pairs[2]\n",
    "    (d1, d2) = rhyme_pairs[3]\n",
    "    (e1, e2) = rhyme_pairs[4]\n",
    "    (f1, f2) = rhyme_pairs[5]\n",
    "    (g1, g2) = rhyme_pairs[6]\n",
    "    \n",
    "    poem += sample_sentence1(hmm, obs_map, a1) + '\\n'\n",
    "    poem += sample_sentence1(hmm, obs_map, b1) + '\\n'\n",
    "    poem += sample_sentence1(hmm, obs_map, a2) + '\\n'\n",
    "    poem += sample_sentence1(hmm, obs_map, b2) + '\\n'\n",
    "    poem += sample_sentence1(hmm, obs_map, c1) + '\\n'\n",
    "    poem += sample_sentence1(hmm, obs_map, d1) + '\\n'\n",
    "    poem += sample_sentence1(hmm, obs_map, c2) + '\\n'\n",
    "    poem += sample_sentence1(hmm, obs_map, d2) + '\\n'\n",
    "    poem += sample_sentence1(hmm, obs_map, e1) + '\\n'\n",
    "    poem += sample_sentence1(hmm, obs_map, f1) + '\\n'\n",
    "    poem += sample_sentence1(hmm, obs_map, e2) + '\\n'\n",
    "    poem += sample_sentence1(hmm, obs_map, f2) + '\\n'\n",
    "    poem += sample_sentence1(hmm, obs_map, g1) + '\\n'\n",
    "    poem += sample_sentence1(hmm, obs_map, g2)\n",
    "    \n",
    "    return poem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import text\n",
    "shakespeare_text = open(os.path.join(os.getcwd(), 'data_Shakespeare/shakespeare.txt')).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into sonnets\n",
    "shakespeare_sonnets = split_by_sonnet_shakespeare(shakespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process text (Remove sonnet number)\n",
    "shakespeare_clean = clean_shakespeare(shakespeare_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Rhyme Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_rhyme_pairs = build_rhyme_pairs_shakespeare(shakespeare_sonnets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Syllables Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllables = open(os.path.join(os.getcwd(), 'data_Shakespeare/Syllable_dictionary.txt')).read()\n",
    "syllables_dict = build_syllables_dict(syllables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "Iteration: 20\n",
      "Iteration: 30\n",
      "Iteration: 40\n",
      "Iteration: 50\n",
      "Iteration: 60\n",
      "Iteration: 70\n",
      "Iteration: 80\n",
      "Iteration: 90\n",
      "Iteration: 100\n"
     ]
    }
   ],
   "source": [
    "# Shakespeare text only\n",
    "obs_reversed_shakespeare, obs_map_reversed_shakespeare = parse_observations_reverse(shakespeare_clean)\n",
    "hmm = unsupervised_HMM(obs_reversed_shakespeare, 16, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thou thou where be leave not am would spend find\n",
      "Highmost made withering willing know thy ranged\n",
      "Lines loves i the self once straight with tell wind\n",
      "One upon thee love's doth esteemed exchanged\n",
      "Else them in than niggard or bad uphold\n",
      "Prognosticate ornament were will black\n",
      "As make to pays need art me eyes bring cold\n",
      "Sweets did together will first all pry lack\n",
      "Live advantage see need expiate case\n",
      "Him doth in doth leave am their brave plight sight\n",
      "I not that do faint give so right dear place\n",
      "Looks away leaped swear my defeated light\n",
      "Say could that hath say the hours hours\n",
      "May evermore my had my fair flowers\n"
     ]
    }
   ],
   "source": [
    "shakespeare_rhyme = random.sample(list(shakespeare_rhyme_pairs.keys()), 7)\n",
    "print(sample_shakespeare_sonnet(hmm, obs_map_reversed_shakespeare, shakespeare_rhyme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

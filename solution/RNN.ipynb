{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "import json\n",
    "from HMM import unsupervised_HMM\n",
    "from HMM_helper import (\n",
    "    text_to_wordcloud,\n",
    "    states_to_wordclouds,\n",
    "    parse_observations,\n",
    "    sample_sentence,\n",
    "    visualize_sparsities,\n",
    "    animate_emission\n",
    ")\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove digits, blank lines, and extra spaces. \n",
    "lines = text.splitlines()\n",
    "all_lines = []\n",
    "\n",
    "for line in lines: \n",
    "    if line.strip().isdigit() == False and len(line) > 1: \n",
    "        clean_line = line.strip().lower()\n",
    "        clean_line = re.sub('[(){}<>]', '', clean_line)\n",
    "        all_lines.append(clean_line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clean poetry lines into a new file\n",
    "with open('ShakespeareLines.txt', 'w') as f:\n",
    "    for line in all_lines:\n",
    "        f.write(line)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import raw Shakespeare lines\n",
    "raw_text = open(os.path.join(os.getcwd(), 'ShakespeareLines.txt')).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all possible sequences of 40 characters\n",
    "seq_len = 40\n",
    "all_sequences = []\n",
    "raw_sequences = ''\n",
    "for i in range(seq_len, len(raw_text)):\n",
    "    seq = raw_text[i-seq_len:i+1]\n",
    "    all_sequences.append(seq)\n",
    "    raw_sequences += seq + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all unique characters\n",
    "chars = sorted(list(set(raw_sequences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot-encoded dictionaries mapping from char to indice and from indice to char\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the sequences with our hot-encoded dictionaries\n",
    "encoded_seq = []\n",
    "for seq in all_sequences:\n",
    "    encoded = [char_indices[char] for char in seq]\n",
    "    encoded_seq.append(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split encoded sequence into X and y for training the model\n",
    "encoded_seq = np.asarray(encoded_seq)\n",
    "X, y = encoded_seq[:,:-1], encoded_seq[:,-1]\n",
    "encoded_seq = [to_categorical(x, num_classes=vocab_size) for x in X]\n",
    "X = np.asarray(encoded_seq)\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model - single layer model with 128 LSTM units and softmax output\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seq_len, vocab_size)))\n",
    "model.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "model.fit(X, y, epochs=60, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature - https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
    "def sample(preds, temperature):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem(seed_text, num_chars, temp): \n",
    "    output = seed_text\n",
    "    for i in range(num_chars):\n",
    "        # Encode the current generated text\n",
    "        encoded = [mapping[char] for char in output]\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_len, truncating='pre')\n",
    "        encoded = to_categorical(encoded, num_classes=len(char_indices))\n",
    "        # Predict next character (using temperature)\n",
    "        pred = model.predict(encoded, verbose=0)[0]\n",
    "        next_index = sample(pred, temp)\n",
    "        output += indices_char[next_index]\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_1 = generate_poem(\"shall i compare thee to a summer’s day?\\n\", 400, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_2 = generate_poem(\"shall i compare thee to a summer’s day?\\n\", 400, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_3 = generate_poem(\"shall i compare thee to a summer’s day?\\n\", 400, 0.25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
